{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "## Modeling \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.sentiment_analyzer import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offenseval-annotation.txt',\n",
       " 'offenseval-training-v1.tsv',\n",
       " 'readme-trainingset-v1.txt']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd()+\"\\\\training-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "with open('.\\\\training-v1\\\\offenseval-training-v1.tsv','r', encoding = 'utf-8') as in_file:\n",
    "    #train_data = [line.strip().split('\\t') for line in in_file]\n",
    "    \n",
    "    for line in in_file:\n",
    "        train_df = pd.concat([train_df,pd.DataFrame([line.strip().split('\\t')])], axis = 0)\n",
    "        \n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyzing the data and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the first row as the column headers\n",
    "train_df.columns = train_df.iloc[0,:].values\n",
    "train_df = train_df.iloc[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62688</td>\n",
       "      <td>\"@USER Someone should'veTaken\"\" this piece of ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     id                                              tweet subtask_a  \\\n",
       "1  0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "2  0  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "3  0  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "4  0  62688  \"@USER Someone should'veTaken\"\" this piece of ...       OFF   \n",
       "5  0  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "1       UNT      NULL  \n",
       "2       TIN       IND  \n",
       "3      NULL      NULL  \n",
       "4       UNT      NULL  \n",
       "5      NULL      NULL  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 6)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of each of the sub-tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    8840\n",
       "OFF    4400\n",
       "Name: subtask_a, dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    8840\n",
       "TIN     3876\n",
       "UNT      524\n",
       "Name: subtask_b, dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    9364\n",
       "IND     2407\n",
       "GRP     1074\n",
       "OTH      395\n",
       "Name: subtask_c, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.subtask_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df.tweet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0</td>\n",
       "      <td>45643</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>0</td>\n",
       "      <td>22953</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>0</td>\n",
       "      <td>60513</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>0</td>\n",
       "      <td>66322</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>0</td>\n",
       "      <td>38491</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>0</td>\n",
       "      <td>73520</td>\n",
       "      <td>@USER Looks Like The Jokes On Liberals Again. ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     id                                              tweet subtask_a  \\\n",
       "1270   0  45643  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "4073   0  22953  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "8333   0  60513  @USER Looks Like The Jokes On Liberals Again. ...       OFF   \n",
       "10460  0  66322  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "10624  0  38491  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "11304  0  73520  @USER Looks Like The Jokes On Liberals Again. ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "1270       NULL      NULL  \n",
       "4073       NULL      NULL  \n",
       "8333        TIN       GRP  \n",
       "10460      NULL      NULL  \n",
       "10624      NULL      NULL  \n",
       "11304      NULL      NULL  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet == '@USER Looks Like The Jokes On Liberals Again.  #FortTrump #Poland #BoomingEconomy URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>0</td>\n",
       "      <td>81140</td>\n",
       "      <td>@USER An obvious last minute liberal ploy to d...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>0</td>\n",
       "      <td>46503</td>\n",
       "      <td>@USER An obvious last minute liberal ploy to d...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     id                                              tweet subtask_a  \\\n",
       "5166  0  81140  @USER An obvious last minute liberal ploy to d...       NOT   \n",
       "5307  0  46503  @USER An obvious last minute liberal ploy to d...       NOT   \n",
       "\n",
       "     subtask_b subtask_c  \n",
       "5166      NULL      NULL  \n",
       "5307      NULL      NULL  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet == \"@USER An obvious last minute liberal ploy to delay confirmation. More dirty tricks since the liberals lost the previous election.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>14617</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>0</td>\n",
       "      <td>16759</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>0</td>\n",
       "      <td>15862</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     id                                              tweet subtask_a  \\\n",
       "2144  0  14617  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "2724  0  16759  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "4223  0  15862  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT   \n",
       "\n",
       "     subtask_b subtask_c  \n",
       "2144      NULL      NULL  \n",
       "2724      NULL      NULL  \n",
       "4223      NULL      NULL  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet ==  \"@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Following all #Maga patriots please follow back ðŸ‘  #LionsDen ðŸ¦  #MAGA2KAG ðŸ‡ºðŸ‡¸\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Sentiment Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity_values = train_df.tweet.apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_array = []\n",
    "\n",
    "for each in sentiment_polarity_values:\n",
    "    temp_polarity_array = list(each.values())\n",
    "    polarity_array.append(temp_polarity_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopword collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting stopwords\n",
    "stop_words_list = stopwords.words('english')\n",
    "tweet_tokens = train_df.tweet.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining all the tokenized words\n",
    "words = ' '.join(words for sent in tweet_tokens.values for words in sent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(words.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting words with frequency 1\n",
    "less_freq_words = [word for (word,count) in word_count.most_common()[-16200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 33437),\n",
       " ('USER', 33412),\n",
       " ('.', 14360),\n",
       " ('the', 8071),\n",
       " ('is', 6392),\n",
       " ('to', 6170),\n",
       " (\"''\", 5565),\n",
       " ('#', 5399),\n",
       " ('a', 5103),\n",
       " ('!', 5099),\n",
       " ('and', 4588),\n",
       " ('you', 4063),\n",
       " ('of', 3731),\n",
       " ('are', 3465),\n",
       " ('I', 3440),\n",
       " ('?', 3016),\n",
       " ('that', 2629),\n",
       " ('in', 2575),\n",
       " ('â€™', 2574),\n",
       " ('for', 2382),\n",
       " ('URL', 2058),\n",
       " ('it', 2026),\n",
       " ('he', 1880),\n",
       " ('...', 1806),\n",
       " ('on', 1648),\n",
       " ('she', 1559),\n",
       " ('not', 1466),\n",
       " ('with', 1450),\n",
       " ('have', 1415),\n",
       " (\"'s\", 1393),\n",
       " ('be', 1373),\n",
       " ('this', 1372),\n",
       " ('``', 1347),\n",
       " (\"n't\", 1289),\n",
       " ('You', 1245),\n",
       " ('do', 1239),\n",
       " (',', 1235),\n",
       " ('they', 1221),\n",
       " ('He', 1159),\n",
       " ('gun', 1144),\n",
       " ('control', 1114),\n",
       " ('all', 1055),\n",
       " ('your', 1047),\n",
       " ('like', 1025),\n",
       " ('s', 995),\n",
       " ('was', 984),\n",
       " ('about', 982),\n",
       " ('as', 976),\n",
       " ('t', 958),\n",
       " ('so', 945),\n",
       " ('her', 933),\n",
       " ('She', 922),\n",
       " ('will', 898),\n",
       " ('MAGA', 883),\n",
       " (';', 883),\n",
       " ('liberals', 866),\n",
       " ('who', 853),\n",
       " ('The', 836),\n",
       " ('what', 828),\n",
       " ('just', 827),\n",
       " ('people', 824),\n",
       " ('but', 786),\n",
       " ('&', 784),\n",
       " ('from', 730),\n",
       " ('has', 721),\n",
       " ('his', 720),\n",
       " ('at', 706),\n",
       " ('by', 704),\n",
       " ('amp', 677),\n",
       " ('we', 676),\n",
       " ('can', 672),\n",
       " ('an', 667),\n",
       " ('up', 665),\n",
       " ('out', 659),\n",
       " ('or', 654),\n",
       " ('their', 648),\n",
       " ('if', 642),\n",
       " ('It', 625),\n",
       " ('my', 618),\n",
       " ('know', 617),\n",
       " ('me', 606),\n",
       " ('Antifa', 603),\n",
       " ('get', 576),\n",
       " ('conservatives', 572),\n",
       " ('one', 567),\n",
       " ('no', 562),\n",
       " ('him', 561),\n",
       " ('more', 542),\n",
       " (':', 540),\n",
       " ('them', 539),\n",
       " ('would', 537),\n",
       " ('how', 537),\n",
       " ('when', 534),\n",
       " ('think', 532),\n",
       " ('Trump', 523),\n",
       " ('Liberals', 501),\n",
       " ('should', 487),\n",
       " ('And', 482),\n",
       " (')', 480),\n",
       " ('because', 470),\n",
       " ('(', 432),\n",
       " ('This', 424),\n",
       " ('our', 414),\n",
       " ('now', 412),\n",
       " ('They', 411),\n",
       " ('We', 410),\n",
       " ('right', 408),\n",
       " ('there', 408),\n",
       " ('-', 378),\n",
       " ('want', 373),\n",
       " ('That', 369),\n",
       " ('only', 366),\n",
       " ('Conservatives', 357),\n",
       " ('did', 357),\n",
       " ('why', 357),\n",
       " ('than', 354),\n",
       " ('time', 346),\n",
       " ('need', 345),\n",
       " ('going', 345),\n",
       " ('been', 335),\n",
       " ('being', 333),\n",
       " ('good', 332),\n",
       " ('antifa', 327),\n",
       " ('does', 324),\n",
       " ('see', 322),\n",
       " ('â€', 321),\n",
       " ('say', 320),\n",
       " ('shit', 319),\n",
       " ('us', 316),\n",
       " ('What', 315),\n",
       " ('â€œ', 313),\n",
       " ('i', 308),\n",
       " ('were', 306),\n",
       " ('If', 304),\n",
       " ('never', 300),\n",
       " ('don', 299),\n",
       " ('go', 298),\n",
       " ('way', 296),\n",
       " ('any', 290),\n",
       " ('back', 290),\n",
       " ('make', 289),\n",
       " ('A', 281),\n",
       " ('So', 278),\n",
       " ('even', 277),\n",
       " ('too', 275),\n",
       " ('other', 273),\n",
       " ('some', 273),\n",
       " ('But', 273),\n",
       " ('still', 273),\n",
       " ('then', 273),\n",
       " ('really', 271),\n",
       " ('had', 271),\n",
       " ('over', 268),\n",
       " ('these', 267),\n",
       " (\"'re\", 267),\n",
       " ('much', 263),\n",
       " ('love', 261),\n",
       " ('Why', 248),\n",
       " ('believe', 241),\n",
       " (\"'m\", 239),\n",
       " ('left', 238),\n",
       " ('better', 235),\n",
       " ('said', 232),\n",
       " ('No', 228),\n",
       " ('man', 228),\n",
       " ('against', 222),\n",
       " ('take', 218),\n",
       " ('most', 217),\n",
       " ('Kavanaugh', 215),\n",
       " ('down', 215),\n",
       " ('country', 214),\n",
       " ('could', 211),\n",
       " ('How', 211),\n",
       " ('into', 209),\n",
       " ('ANTIFA', 209),\n",
       " ('doing', 205),\n",
       " ('those', 205),\n",
       " ('also', 201),\n",
       " ('thing', 201),\n",
       " ('very', 201),\n",
       " ('years', 200),\n",
       " ('many', 198),\n",
       " ('m', 196),\n",
       " ('here', 196),\n",
       " ('Gun', 195),\n",
       " ('Do', 189),\n",
       " ('well', 188),\n",
       " ('support', 186),\n",
       " ('Democrats', 186),\n",
       " ('vote', 186),\n",
       " ('am', 185),\n",
       " ('trying', 185),\n",
       " ('2', 183),\n",
       " ('same', 181),\n",
       " ('off', 181),\n",
       " ('sure', 181),\n",
       " ('got', 180),\n",
       " ('money', 179),\n",
       " ('laws', 178),\n",
       " ('party', 177)]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_words = [word for (word,count) in word_count.most_common(100)]\n",
    "words_to_keep = ['gun','MAGA','liberals','Antifa','conservatives','Trump','Liberals','amp','people','control']\n",
    "\n",
    "_ = [high_freq_words.remove(each) for each in words_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list.extend(less_freq_words)\n",
    "stop_words_list.extend(high_freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokens_clean = tweet_tokens.apply(lambda x: [words for words in x if words not in stop_words_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokens_clean_list = [list(np.where(len(each) > 0,each,['UNK'])) for each in tweet_tokens_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(tweet_tokens_clean_list, size = 200, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "random_array = np.random.rand(100)\n",
    "embedding_list = []\n",
    "for each in tweet_tokens_clean_list:\n",
    "    if(len(each) == 0):\n",
    "        embedding_list.append(list(random_array))\n",
    "    else:\n",
    "        embedding_list.append(list(np.mean(model[each],axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_df = pd.DataFrame(embedding_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Number of Hashtags and Number of User count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_token_space = train_df.tweet.apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = tweet_token_space.apply(lambda x:  len( [each for each in x if each.startswith('@')])).values\n",
    "hast_tag_counts = tweet_token_space.apply(lambda x:  len( [each for each in x if each.startswith('#')])).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2ngrams(text, n=3, exact=True):\n",
    "    \"\"\" Convert text into character ngrams. \"\"\"\n",
    "    return [\"\".join(j) for j in zip(*[text[i:] for i in range(n)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_3_gram = train_df.tweet.apply(word2ngrams,n = 3)\n",
    "char_4_gram = train_df.tweet.apply(word2ngrams,n = 4)\n",
    "char_5_gram = train_df.tweet.apply(word2ngrams,n = 5)\n",
    "char_6_gram = train_df.tweet.apply(word2ngrams,n = 6)\n",
    "char_7_gram = train_df.tweet.apply(word2ngrams,n = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_3_gram_dict = {}\n",
    "char_4_gram_dict = {}\n",
    "char_5_gram_dict = {}\n",
    "char_6_gram_dict = {}\n",
    "char_7_gram_dict = {}\n",
    "\n",
    "for row_num, text in enumerate(train_df.tweet):\n",
    "    char_3_gram_dict[text] = char_3_gram.values[row_num]\n",
    "    char_4_gram_dict[text] = char_4_gram.values[row_num]\n",
    "    char_5_gram_dict[text] = char_5_gram.values[row_num]\n",
    "    char_6_gram_dict[text] = char_6_gram.values[row_num]\n",
    "    char_7_gram_dict[text] = char_7_gram.values[row_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Dictionary of cuss words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuss_words_df = pd.DataFrame()\n",
    "\n",
    "for alphas in list(string.ascii_lowercase):\n",
    "    #print(alphas)\n",
    "    url = \"https://www.noswearing.com//dictionary//\"+alphas\n",
    "    XML = requests.get(url)\n",
    "\n",
    "    tree = html.fromstring(XML.content)\n",
    "    \n",
    "    td_files = tree.xpath(\"//center\")[4].getchildren()[0].getchildren()[1].getchildren()[0].getchildren()[0]\n",
    "\n",
    "    for tags in td_files.getchildren():\n",
    "        if(tags.text != None):\n",
    "\n",
    "            #print(tags.text)\n",
    "            #print(tags.tail)\n",
    "            test = pd.DataFrame({'Cuss_word':[tags.text.strip()],'Meaning':[tags.tail.replace(\"-\",\"\").strip()]})\n",
    "            cuss_words_df = pd.concat([cuss_words_df,test],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuss_words_df.reset_index(inplace=True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuss_word</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anus</td>\n",
       "      <td>butt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arse</td>\n",
       "      <td>butt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arsehole</td>\n",
       "      <td>butt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ass</td>\n",
       "      <td>butt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ass-hat</td>\n",
       "      <td>idiot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cuss_word Meaning\n",
       "0      anus    butt\n",
       "1      arse    butt\n",
       "2  arsehole    butt\n",
       "3       ass    butt\n",
       "4   ass-hat   idiot"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuss_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_pos = train_df.tweet.apply(lambda x: (x.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer\n",
    "stop_words_list.append('user')\n",
    "stop_words_list.append('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_counts_char_n_gram = CountVectorizer(tokenizer=lambda key: char_4_gram_dict[key],\n",
    "                                         preprocessor= lambda x:x, lowercase=False,stop_words = stop_words_list)\n",
    "bow_data_char_n_gram = bow_counts_char_n_gram.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_counts = CountVectorizer(tokenizer= word_tokenize, stop_words = stop_words_list,ngram_range=(1,2))\n",
    "bow_data = bow_counts.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_counts_char_gram = TfidfVectorizer(tokenizer=lambda key: char_5_gram_dict[key], preprocessor= lambda x:x, lowercase=False)\n",
    "tfidf_data_char_gram = tfidf_counts_char_gram.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_counts = TfidfVectorizer(tokenizer=word_tokenize, stop_words = stop_words_list,ngram_range=(1,3),)\n",
    "tfidf_data = tfidf_counts.fit_transform(train_df.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senti_analyser = SentimentAnalyzer()\n",
    "#senti_analyser.all_words(train_df.tweet.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_data2 = np.concatenate((list(user_counts),embedding_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_embeddings_df = word_embeddings_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(user_counts,hast_tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input data\n",
    "#tfidf_data_char_gram\n",
    "X = sp.sparse.hstack((bow_data,bow_data_char_n_gram,tfidf_data),format='csr')\n",
    "\n",
    "### Input Column names\n",
    "X_columns=bow_counts.get_feature_names()+  \\\n",
    "            bow_counts_char_n_gram.get_feature_names()+\\\n",
    "                    tfidf_counts.get_feature_names()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X,train_df.subtask_a,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 :  0.7534852387252842\n",
      "1 :  0.7537323564566173\n",
      "2 :  0.7501793131352553\n",
      "0.5 :  0.7537325258552041\n"
     ]
    }
   ],
   "source": [
    "for C in [0.75,1,2,0.5]:\n",
    "    lr_model = LogisticRegression(C = C)\n",
    "    lr_model.fit(X_train,y_train)\n",
    "    test_pred = lr_model.predict(X_test)\n",
    "\n",
    "    #acc = 100 * np.sum(test_pred == y_test)/len(y_test)\n",
    "    print(C,\": \",f1_score(y_test,test_pred,average='weighted') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662386706948641"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == test_pred).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 50)\n",
    "rf_model.fit(X_train,y_train)\n",
    "test_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 :  0.7365723641233011\n",
      "Acc: 76.54833836858006\n"
     ]
    }
   ],
   "source": [
    "acc = 100 * np.sum(test_pred == y_test)/len(y_test)\n",
    "print(\"F1 : \",f1_score(y_test,test_pred,average='weighted'))\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators = 500, max_depth= 6,learning_rate = 0.3)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "test_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 :  0.7678135614867583\n",
      "Acc: 77.9833836858006\n"
     ]
    }
   ],
   "source": [
    "acc = 100 * np.sum(test_pred == y_test)/len(y_test)\n",
    "print(\"F1 : \",f1_score(y_test,test_pred,average='weighted'))\n",
    "print(\"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 20\n",
    "top_features = np.array(X_columns)[(-np.abs(lr_model.coef_)).argsort()[0][0:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ouch!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ws. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ews.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>liar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ot we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>liar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ouch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is! ðŸ’¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e a m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ðŸ’¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   hing!\n",
       "1   Ouch!\n",
       "2   ws. .\n",
       "3    fuck\n",
       "4    fuck\n",
       "5    shit\n",
       "6   bitch\n",
       "7     ass\n",
       "8   ews. \n",
       "9    shit\n",
       "10   liar\n",
       "11  hing.\n",
       "12   fool\n",
       "13  ot we\n",
       "14   liar\n",
       "15  Ouch.\n",
       "16  is! ðŸ’¥\n",
       "17  e a m\n",
       "18      ðŸ’¥\n",
       "19  awful"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some of the misclassified tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_tweets = train_df.iloc[(y_test[(y_test != test_pred)].index.values - 1).tolist(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  148, 12436,  1748,  9803, 10525], dtype=int64)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[(y_test != test_pred)].index.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inputs with misclassification\n",
    "\n",
    "X_test_misclassified = X_test.toarray()[(y_test != test_pred),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>68629</td>\n",
       "      <td>@USER Let the leftist democrats riot in the st...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12436</th>\n",
       "      <td>0</td>\n",
       "      <td>43619</td>\n",
       "      <td>\".....\"\"  And he is shuting up.  Don't mess wi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>0</td>\n",
       "      <td>99677</td>\n",
       "      <td>@USER The #metoo movement has turned out just ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9803</th>\n",
       "      <td>0</td>\n",
       "      <td>37881</td>\n",
       "      <td>@USER He is the worst person.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10525</th>\n",
       "      <td>0</td>\n",
       "      <td>72803</td>\n",
       "      <td>@USER you are a DISGRACE</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>0</td>\n",
       "      <td>93549</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0</td>\n",
       "      <td>69659</td>\n",
       "      <td>@USER Do not think so maybe do a little resear...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>0</td>\n",
       "      <td>42219</td>\n",
       "      <td>\"@USER There are deals on Mexico EU trade and ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>0</td>\n",
       "      <td>37828</td>\n",
       "      <td>@USER She is by far the most pretentious littl...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12530</th>\n",
       "      <td>0</td>\n",
       "      <td>81420</td>\n",
       "      <td>@USER @USER Liberals didn't want to hear from ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     id                                              tweet subtask_a  \\\n",
       "148    0  68629  @USER Let the leftist democrats riot in the st...       OFF   \n",
       "12436  0  43619  \".....\"\"  And he is shuting up.  Don't mess wi...       OFF   \n",
       "1748   0  99677  @USER The #metoo movement has turned out just ...       NOT   \n",
       "9803   0  37881                      @USER He is the worst person.       OFF   \n",
       "10525  0  72803                           @USER you are a DISGRACE       OFF   \n",
       "4476   0  93549  @USER @USER @USER @USER @USER @USER @USER @USE...       OFF   \n",
       "4270   0  69659  @USER Do not think so maybe do a little resear...       OFF   \n",
       "3919   0  42219  \"@USER There are deals on Mexico EU trade and ...       OFF   \n",
       "9493   0  37828  @USER She is by far the most pretentious littl...       OFF   \n",
       "12530  0  81420  @USER @USER Liberals didn't want to hear from ...       OFF   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "148         TIN       IND  \n",
       "12436       TIN       IND  \n",
       "1748       NULL      NULL  \n",
       "9803        TIN       IND  \n",
       "10525       TIN       IND  \n",
       "4476        UNT      NULL  \n",
       "4270        TIN       OTH  \n",
       "3919        UNT      NULL  \n",
       "9493        TIN       IND  \n",
       "12530       TIN       IND  "
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>68629</td>\n",
       "      <td>@USER Let the leftist democrats riot in the st...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     id                                              tweet subtask_a  \\\n",
       "148  0  68629  @USER Let the leftist democrats riot in the st...       OFF   \n",
       "\n",
       "    subtask_b subtask_c  \n",
       "148       TIN       IND  "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#misclassified_tweets.to_csv('misclassified_tweets.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.389097</th>\n",
       "      <td>church</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>church god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.755536</th>\n",
       "      <td>disgusting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>disgusting going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.699415</th>\n",
       "      <td>god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.753855</th>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002113</th>\n",
       "      <td>going taking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.856062</th>\n",
       "      <td>taking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>taking whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.368911</th>\n",
       "      <td>whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>whole church</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "-0.389097             church\n",
       " 0.000000         church god\n",
       " 10.755536        disgusting\n",
       " 0.000000   disgusting going\n",
       "-2.699415                god\n",
       "-2.753855              going\n",
       " 0.002113       going taking\n",
       "-1.856062             taking\n",
       " 0.000000       taking whole\n",
       " 1.368911              whole\n",
       " 0.000000       whole church"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_of_misclassified = 3\n",
    "\n",
    "\n",
    "non_zero_features = [pos for pos,each in enumerate(X_test_misclassified[position_of_misclassified]) if each > 0]\n",
    "\n",
    "tokens = np.array(bow_counts.get_feature_names())[non_zero_features]\n",
    "\n",
    "words = [bow_counts.get_feature_names().index(each) for each in tokens]\n",
    "score = [lr_model.coef_[0][each] for each in words]\n",
    "\n",
    "pd.DataFrame(tokens,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OFF    369\n",
       "NOT     61\n",
       "Name: subtask_a, dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.tweet.str.contains('shit')].subtask_a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 :  72.84743202416918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1629,  141],\n",
       "       [ 578,  300]], dtype=int64)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(C = 2500)\n",
    "lr_model.fit(X_train,y_train)\n",
    "test_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(C,\": \",100 * np.sum(test_pred == y_test)/len(y_test))\n",
    "confusion_matrix(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984123845797418"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "test_pred = lr_model.predict(X_test)\n",
    "f1_score(y_test,test_pred,average='weighted') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell('helooo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = '@USER Ã°Å¸â€˜Å’Ã°Å¸ÂÂ» IÃ¢â‚¬â„¢ve never seen anyone talk like that on Twitter before and IÃ¢â‚¬â„¢ve seen some really messed up shit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell('he!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "word = 'helllllllo'\n",
    "word_wlf = reduce_lengthening(word)\n",
    "spell(word_wlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
